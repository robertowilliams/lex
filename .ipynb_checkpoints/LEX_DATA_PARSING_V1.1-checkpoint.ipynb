{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEX PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NATURAL LANGUAGE PROCESSING PROTOTYPE\n",
    "\n",
    "## DATA PARSING\n",
    "\n",
    "***\n",
    "\n",
    "### Version 1.1\n",
    "### Date: Aug 19th, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Version\t|   Description|\n",
    "|:---:|:---|\n",
    "|  0.7 \t|Initial version. Parsing tests to receive datasets from copy/paste from Bianca.|\n",
    "| 0.8 |Tests using Regex with Vipin example. http://www.vipinajayakumar.com/parsing-text-with-python/|\n",
    "|  0.9 \t|Parsing based on 0.8 with limited features.|\n",
    "|  1.0 \t|First sucessfull test with new adaptations.|\n",
    "|  1.1 \t|New RegEX algorithm.|\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a test Jupyter notebook to create a prototype of NLP Classifier to be applied to Legal Documents.\n",
    "This notebook has the objective of DATA PARSING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# personal setup\n",
    "H = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Importing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.ipynb_checkpoints',\n",
       " 'codes',\n",
       " 'DATASETS',\n",
       " 'electronics',\n",
       " 'EXAMPLE-TEST-V1.ipynb',\n",
       " 'EXAMPLE.ipynb',\n",
       " 'images',\n",
       " 'LEX_PROJECT-V3.ipynb',\n",
       " 'LEX_PROJECT_DATA_PARSING_V0.7.ipynb',\n",
       " 'LEX_PROJECT_DATA_PARSING_V0.8.ipynb',\n",
       " 'LEX_PROJECT_DATA_PARSING_V0.9-test.ipynb',\n",
       " 'LEX_PROJECT_DATA_PARSING_V0.9.ipynb',\n",
       " 'LEX_PROJECT_DATA_PARSING_V1.0.ipynb',\n",
       " 'OLD',\n",
       " 'PackPub',\n",
       " 'spam.csv',\n",
       " 'stopwords.txt',\n",
       " 'Support_Notebooks',\n",
       " 'UDEMY']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '3rdPhase',\n",
       " 'EMENTAS TJ PLANO DE SAÚDE 01082018.txt',\n",
       " 'EMENTAS TJ PLANO DE SAÚDE 03082018.txt',\n",
       " 'EMENTAS TJ PLANO DE SAÚDE 10082018.txt',\n",
       " 'OLD']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.mkdir('dataset_test')\n",
    "os.chdir('DATASETS')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with the regex rules.\n",
    "rx_dict = {\n",
    "        'order': re.compile(r'(?P<order>^[\\d]{1,6})\\s-.*\\n'), # changed\n",
    "    \n",
    "        'number' : re.compile(r'(?P<number>^[\\d]{7}-[\\d]{2}\\.[\\d]{4}\\.[\\d]{1}\\.[\\d]{2}\\.[\\d]{4})'), # kept\n",
    "    \n",
    "        'classe' : re.compile(r'^Classe/Assunto: (?P<classe>.*)\\n'),\n",
    "    \n",
    "        'relator' : re.compile(r'^Relator\\(a\\): (?P<relator>.*)\\n'),\n",
    "    \n",
    "        'comarca' : re.compile(r'^Comarca: (?P<comarca>.*)\\n'),\n",
    "    \n",
    "        'org_julgador' : re.compile(r'^.rg.o julgador: (?P<org_julgador>.*)\\n'),\n",
    "    \n",
    "        'data_julgamento' : re.compile(r'^Data do julgamento: (?P<data_julgamento>.*)\\n'),\n",
    "    \n",
    "        'data_publicacao' : re.compile(r'^Data de publica..o: (?P<data_publicacao>.*)\\n'),\n",
    "    \n",
    "        'data_registro' : re.compile(r'^Data de registro: (?P<data_registro>.*)\\n'),\n",
    "    \n",
    "        'ementa' : re.compile(r'^Ementa: (?P<ementa>.*)\\X')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_line(line):\n",
    "    for key, rx in rx_dict.items():\n",
    "        match = rx.search(line)\n",
    "        if match:\n",
    "            return key, match\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(filepath):\n",
    "    \n",
    "    data = []  # create an empty list to collect the data\n",
    "    \n",
    "    # declaring the variables\n",
    "    order = ''\n",
    "    number = ''\n",
    "    classe = ''\n",
    "    relator = ''\n",
    "    comarca = ''\n",
    "    org_julgador = ''\n",
    "    data_julgamento = ''\n",
    "    data_publicacao = ''\n",
    "    data_registro = ''\n",
    "    ementa = ''\n",
    "\n",
    "    # open the file and read through it line by line\n",
    "    with open(filepath, 'r') as file_object:\n",
    "        \n",
    "        line = file_object.readline()\n",
    "        \n",
    "        while line:\n",
    "            # at each line check for a match with a regex\n",
    "            key, match = _parse_line(line)\n",
    "            \n",
    "            # extract ordered\n",
    "            if key == 'order':\n",
    "                order = match.group('order')\n",
    "            # extract number\n",
    "            if key == 'number':\n",
    "                number = match.group('number')           \n",
    "            # extract classe\n",
    "            if key == 'classe':\n",
    "                classe = match.group('classe')     \n",
    "            # extract relator\n",
    "            if key == 'relator':\n",
    "                relator = match.group('relator')\n",
    "            # extract comarca\n",
    "            if key == 'comarca':\n",
    "                comarca = match.group('comarca')\n",
    "            # extract org_julgador\n",
    "            if key == 'org_julgador':\n",
    "                org_julgador = match.group('org_julgador')\n",
    "            # extract data_julgamento\n",
    "            if key == 'data_julgamento':\n",
    "                data_julgamento = match.group('data_julgamento')\n",
    "            # extract data_publicacao\n",
    "            if key == 'data_publicacao':\n",
    "                data_publicacao = match.group('data_publicacao')\n",
    "            # extract data_registro\n",
    "            if key == 'data_registro':\n",
    "                data_registro = match.group('data_registro')\n",
    "            # extract ementa\n",
    "            if key == 'ementa':\n",
    "                ementa = match.group('ementa')\n",
    "                \n",
    "            # create a dictionary containing this row of data\n",
    "            row = {\n",
    "                'Order': order,'Number': number,'Classe': classe,\n",
    "                'Relator': relator,'Comarca': comarca,'Org_julgador': org_julgador,\n",
    "                'Data_julgamento': data_julgamento,'Data_publicacao': data_publicacao,\n",
    "                'Data_registro': data_registro,'Ementa': ementa\n",
    "                    }\n",
    "            # append the dictionary to the data list\n",
    "            data.append(row)\n",
    "            break\n",
    "\n",
    "        # create a pandas DataFrame from the list of dicts\n",
    "        data = pd.DataFrame(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '3rdPhase_test_v2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '3rdPhase_test_v2.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-636097d7f0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-339038f57aff>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# open the file and read through it line by line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '3rdPhase_test_v2.txt'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = parse(filepath)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
