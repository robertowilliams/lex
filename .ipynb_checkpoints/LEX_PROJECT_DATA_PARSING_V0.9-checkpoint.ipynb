{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEX PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NATURAL LANGUAGE PROCESSING PROTOTYPE\n",
    "\n",
    "## DATA PARSING\n",
    "\n",
    "***\n",
    "\n",
    "### Version 0.95\n",
    "### Date: July 28th, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Version\t|   Description|\n",
    "|:---:|:---|\n",
    "|  0.95 \t|   Dataset parsing tests.|\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a test Jupyter notebook to create a prototype of NLP Classifier to be applied to Legal Documents.\n",
    "This notebook has the objective of DATA CLEANING."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# personal setup\n",
    "H = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Importing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.ipynb_checkpoints',\n",
       " 'codes',\n",
       " 'DATASETS',\n",
       " 'electronics',\n",
       " 'EXAMPLE-TEST-V1.ipynb',\n",
       " 'EXAMPLE.ipynb',\n",
       " 'images',\n",
       " 'LEX_PROJECT-V3.ipynb',\n",
       " 'LEX_PROJECT_DASK_V1.ipynb',\n",
       " 'LEX_PROJECT_DATA_CLEANING_V1.ipynb',\n",
       " 'LEX_PROJECT_DATA_CLEANING_V2-Copy1.1.ipynb',\n",
       " 'LEX_PROJECT_DATA_CLEANING_V2.1.ipynb',\n",
       " 'LEX_PROJECT_DATA_CLEANING_V2.ipynb',\n",
       " 'LEX_PROJECT_SCRAPING_V1.ipynb',\n",
       " 'OLD',\n",
       " 'PackPub',\n",
       " 'spam.csv',\n",
       " 'stopwords.txt',\n",
       " 'Support_Notebooks',\n",
       " 'UDEMY']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '1st_phase',\n",
       " '3rdPhase_test_v1.txt',\n",
       " '3rdPhase_test_v2.txt',\n",
       " 'import_io',\n",
       " 'sample.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.mkdir('dataset_test')\n",
    "os.chdir('DATASETS')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with the regex rules.\n",
    "rx_dict = {\n",
    "        'order': re.compile(r'(?P<order>^[\\d]{1,6}\\s-\\s\\s\\n)'),\n",
    "        'number' : re.compile(r'(?P<number>^[\\d]{7}-[\\d]{2}\\.[\\d]{4}\\.[\\d]{1}\\.[\\d]{2}\\.[\\d]{4})'),\n",
    "        'classe' : re.compile(r'(?P<classe>^Classe/Assunto: .*)\\n'),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_line(line):\n",
    "    for key, rx in rx_dict.items():\n",
    "        match = rx.search(line)\n",
    "        if match:\n",
    "            return key, match\n",
    "    # if there are no matches\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(filepath):\n",
    "    data = []  # create an empty list to collect the data\n",
    "    # declaring the variables\n",
    "\n",
    "    order = ''\n",
    "    number = ''\n",
    "    classe = ''\n",
    "\n",
    "    # open the file and read through it line by line\n",
    "    with open(filepath, 'r') as file_object:\n",
    "        line = file_object.readline()\n",
    "        while line:\n",
    "            # at each line check for a match with a regex\n",
    "            key, match = _parse_line(line)\n",
    "            # extract ordered\n",
    "            if key == 'order':\n",
    "                order = match.group('order')\n",
    "            # extract number\n",
    "            if key == 'number':\n",
    "                number = match.group('number')           \n",
    "            # extract classe\n",
    "            if key == 'classe':\n",
    "                classe = match.group('classe')\n",
    "            # create a dictionary containing this row of data\n",
    "            row = {\n",
    "                'Order': order,\n",
    "                'Number': number,\n",
    "                'Classe': classe,\n",
    "                }\n",
    "            # append the dictionary to the data list\n",
    "            data.append(row)\n",
    "            line = file_object.readline()\n",
    "\n",
    "        # create a pandas DataFrame from the list of dicts\n",
    "        data = pd.DataFrame(data)\n",
    "        # set the index\n",
    "        data.set_index(['Order', 'Number', 'Classe'], inplace=True)\n",
    "        # consolidate df to remove nans\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '3rdPhase_test_v2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [(, , ), (, 0007591-65.2015.8.26.0526, ), (, 0007591-65.2015.8.26.0526, Classe/Assunto: Apelação / Planos de Saúde), (, 0007591-65.2015.8.26.0526, Classe/Assunto: Apelação / Planos de Saúde), (, 0007591-65.2015.8.26.0526, Classe/Assunto: Apelação / Planos de Saúde), (, 0007591-65.2015.8.26.0526, Classe/Assunto: Apelação / Planos de Saúde), (, 0007591-65.2015.8.26.0526, Classe/Assunto: Apelação / Planos de Saúde), (, 0007591-65.2015.8.26.0526, Classe/Assunto: Apelação / Planos de Saúde), (, 0007591-65.2015.8.26.0526, Classe/Assunto: Apelação / Planos de Saúde), (, 0007591-65.2015.8.26.0526, Classe/Assunto: Apelação / Planos de Saúde), (, 0007591-65.2015.8.26.0526, Classe/Assunto: Apelação / Planos de Saúde)]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = parse(filepath)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
