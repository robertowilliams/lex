{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEX PROJECT\n",
    "## NATURAL LANGUAGE PROCESSING PROTOTYPE\n",
    "## DATA PARSING\n",
    "***\n",
    "### Version 2.3\n",
    "### Date: Aug 25nd, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Version\t|   Description| Date |\n",
    "|:---:|:---|:---:|\n",
    "|  0.7 \t|Initial version. Parsing tests to receive datasets from copy/paste from Bianca.|July 25th, 2018|\n",
    "| 0.8 |Tests using Regex with Vipin example. http://www.vipinajayakumar.com/parsing-text-with-python/|July 27th, 2018|\n",
    "|  0.9 \t|Parsing based on 0.8 with limited features.|July 28th, 2018|\n",
    "|  1.0 \t|First sucessfull test with new adaptations.|July 28th, 2018|\n",
    "|  1.1 \t|New RegEX algorithm.|Aug 19th, 2018|\n",
    "|  2.0 \t|MAJOR CHANGE: using JSON format as the output std.| June 22nd, 2018|\n",
    "|  2.1 \t|First prototype with json approach.|Aug 24th, 2018|\n",
    "|  2.2 \t|Separated each PATTERN .|Aug 24th, 2018|\n",
    "| 2.3   |Changing the json format.|Aug 25th,2018|\n",
    "\n",
    "***\n",
    "NOTES:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a test Jupyter notebook to create a prototype of NLP Classifier to be applied to Legal Documents.\n",
    "This notebook has the objective of DATA PARSING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "import re\n",
    "import time\n",
    "\n",
    "# personal setup\n",
    "H = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Importing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.ipynb_checkpoints',\n",
       " 'CLEANING',\n",
       " 'DASK',\n",
       " 'DATASETS',\n",
       " 'images',\n",
       " 'LEX_DATA_PARSING_V1.1.ipynb',\n",
       " 'LEX_PREDICTION-V3.ipynb',\n",
       " 'LEX_PROJECT_DATA_PARSING_V2.0.ipynb',\n",
       " 'LEX_PROJECT_DATA_PARSING_V2.1.ipynb',\n",
       " 'LEX_PROJECT_DATA_PARSING_V2.2.ipynb',\n",
       " 'LEX_PROJECT_DATA_PARSING_V2.3.ipynb',\n",
       " 'PARSING',\n",
       " 'PREDICTION',\n",
       " 'REGEX_EXPRESSIONS_TESTS',\n",
       " 'SCRAPING',\n",
       " 'SUPPORT_NOTEBOOKS']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'EMENTAS TJ PLANO DE SAÚDE 20082018.txt',\n",
       " 'EMENTAS.txt',\n",
       " 'EMENTAS.txt.json',\n",
       " 'OLD']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.mkdir('DATASETS/dataset_test')\n",
    "os.chdir('DATASETS/2ND_PHASE')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PARSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Class Verdicts with variable with placeholders.\n",
    "class Verdicts:\n",
    "    def __init__(self):\n",
    "        self.order = [] #  \n",
    "        self.number = [] # \n",
    "        self.classe = [] # \n",
    "        self.relator = [] # \n",
    "        self.comarca = [] # \n",
    "        self.org_julgador = [] # \n",
    "        self.data_julgamento = [] # \n",
    "        self.data_publicacao = [] # \n",
    "        self.data_registro = [] #         \n",
    "        self.ementa = [] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/3768895/how-to-make-a-class-json-serializable\n",
    "class MyEncoder(JSONEncoder):\n",
    "    def default(self, o):\n",
    "        return o.__dict__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ementa(file_list):    \n",
    "    \n",
    "    # Patterns to extract Data.\n",
    "    ORDER = r'^(?P<order>^[\\d]{1,6})\\s-.*\\n'\n",
    "    NUMBER = r'^(?P<number>^[\\d]{7}-[\\d]{2}\\.[\\d]{4}\\.[\\d]{1}\\.[\\d]{2}\\.[\\d]{4})'\n",
    "    CLASSE = r'^Classe/Assunto: (?P<classe>.*)\\n'\n",
    "    RELATOR = r'^Relator\\(a\\): (?P<relator>.*)\\n'\n",
    "    COMARCA = r'^Comarca: (?P<comarca>.*)\\n'\n",
    "    ORG_JULGADOR = r'^.rg.o julgador: (?P<org_julgador>.*)\\n'\n",
    "    DATA_JULGAMENTO = r'^Data do julgamento: (?P<data_julgamento>.*)\\n'\n",
    "    DATA_PUBLICACAO = r'^Data de publica.+: (?P<data_julgamento>.*)\\n'\n",
    "    DATA_REGISTRO = r'^Data de registro: (?P<data_registro>.*)\\n'\n",
    "    EMENTA = r'^Ementa: (?P<ementa>.*)\\n'\n",
    "    \n",
    "    # For Loop definition.\n",
    "    for file_name in file_list:\n",
    "        # Instance of Verdict into variable.\n",
    "        verdicts = Verdicts()\n",
    "        verdicts.verdict_file_name = file_name\n",
    "        \n",
    "        # Reaading the file name from the list 'file_list'\n",
    "        with open(file_name,'r', encoding='latin1') as rdr:     \n",
    "            \n",
    "            # Another Loop For to read the file content.\n",
    "            for line in rdr:\n",
    "                \n",
    "                match = re.search(ORDER, line)\n",
    "                if match:\n",
    "                    verdicts.order.append(match.group('order'))\n",
    "                    \n",
    "                match = re.search(NUMBER, line)\n",
    "                if match:\n",
    "                    verdicts.number.append(match.group('number'))\n",
    "                    \n",
    "                match = re.search(CLASSE, line)\n",
    "                if match:\n",
    "                    verdicts.classe.append(match.group('classe'))\n",
    "                    \n",
    "                match = re.search(RELATOR, line)\n",
    "                if match:\n",
    "                    verdicts.relator.append(match.group('relator'))                    \n",
    "                    \n",
    "                match = re.search(COMARCA, line)\n",
    "                if match:\n",
    "                    verdicts.comarca.append(match.group('comarca'))\n",
    "                    \n",
    "                match = re.search(ORG_JULGADOR, line)\n",
    "                if match:\n",
    "                    verdicts.org_julgador.append(match.group('org_julgador'))\n",
    "                    \n",
    "                match = re.search(DATA_JULGAMENTO, line)\n",
    "                if match:\n",
    "                    verdicts.data_julgamento.append(match.group('data_julgamento'))\n",
    "                    \n",
    "                match = re.search(DATA_REGISTRO, line)\n",
    "                if match:\n",
    "                    verdicts.data_registro.append(match.group('data_registro'))                    \n",
    "                                    \n",
    "                match = re.search(EMENTA, line)\n",
    "                if match:\n",
    "                    verdicts.ementa.append(match.group('ementa'))    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            with open(file_name+'.json','w', encoding='latin1') as wr:\n",
    "                json.dump(verdicts, wr, ensure_ascii=False, cls=MyEncoder, indent=True)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'EMENTAS TJ PLANO DE SAÚDE 20082018.txt',\n",
       " 'EMENTAS.txt',\n",
       " 'EMENTAS.txt.json',\n",
       " 'EMENTAS_SHORT.txt',\n",
       " 'OLD']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed seconds: 0.19s\n"
     ]
    }
   ],
   "source": [
    "file_list = [r'/Volumes/DOCS/MONIDRA/LEX/NOTEBOOK/DATASETS/2ND_PHASE/EMENTAS_SHORT.txt']\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "parse_ementa(file_list)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print('Elapsed seconds: {0:.2f}s'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
